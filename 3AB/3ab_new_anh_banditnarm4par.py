# -*- coding: utf-8 -*-
"""3AB_new_ANH_banditNarm4par.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1naK6Phqllxbgl2jSzRmWZfVf5s4cDOoS
"""

!pip install pystan>=3.0 arviz

# Import libraries
import stan
import arviz as az
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#dataframe df
df = pd.read_csv('merged_ANH_stan.csv')

# Determine the number of unique subjects and the maximum number of trials
unique_subjects = df['subjid'].unique()
N = len(unique_subjects)
max_trials = df.groupby('subjid').size().max()

# Initialize the Tsubj array and matrices for rew, los, and choice
Tsubj = []
rew_matrix = np.zeros((N, max_trials))
los_matrix = np.zeros((N, max_trials))
choice_matrix = np.zeros((N, max_trials), dtype=int)

# Define the column name that contains subject IDs
subject_id_column = 'subjid'

# Populate the matrices and Tsubj array
for idx, subj in enumerate(unique_subjects):
    subj_data = df[df['subjid'] == subj]
    Tsubj.append(len(subj_data))
    rew_matrix[idx, :len(subj_data)] = subj_data['gain']
    los_matrix[idx, :len(subj_data)] = subj_data['loss']
    choice_matrix[idx, :len(subj_data)] = subj_data['choice']

# Calculate Narm (number of unique choices) and add to stan_data
Narm = df['choice'].nunique()

# Prepare data for Stan model
stan_data = {
    'N': N,
    'T': max_trials,
    'Tsubj': Tsubj,
    'rew': rew_matrix,
    'los': los_matrix,
    'choice': choice_matrix,
    'Narm': Narm  # Include Narm in the data dictionary
}

# Check shapes of the matrices
assert rew_matrix.shape == (N, max_trials), "Incorrect shape for rew_matrix"
assert los_matrix.shape == (N, max_trials), "Incorrect shape for los_matrix"
assert choice_matrix.shape == (N, max_trials), "Incorrect shape for choice_matrix"

# Check the first few rows of the matrices to inspect the content
print("Rew Matrix Sample:", rew_matrix[:5])
print("Los Matrix Sample:", los_matrix[:5])
print("Choice Matrix Sample:", choice_matrix[:5])

# Check the Tsubj array for correct lengths
assert len(Tsubj) == N, "Incorrect length for Tsubj array"
print("Tsubj Sample:", Tsubj[:5])

stan_model_code = """
// Seymour et al 2012 J neuro model, w/o C (chioce perseveration)
data {
  int<lower=1> N;
  int<lower=1> T;
  int<lower=1, upper=T> Tsubj[N];
  real rew[N, T];
  real los[N, T];
  int choice[N, T];
  int Narm;
}

transformed data {
  vector[Narm] initV;
  initV = rep_vector(0.0, Narm);
}

parameters {
  // Declare all parameters as vectors for vectorizing
  // Hyper(group)-parameters
  vector[4] mu_pr;
  vector<lower=0>[4] sigma;

  // Subject-level raw parameters (for Matt trick)
  vector[N] Arew_pr;
  vector[N] Apun_pr;
  vector[N] R_pr;
  vector[N] P_pr;
}

transformed parameters {
  // Transform subject-level raw parameters
  vector<lower=0, upper=1>[N] Arew;
  vector<lower=0, upper=1>[N] Apun;
  vector<lower=0, upper=30>[N] R;
  vector<lower=0, upper=30>[N] P;

  for (i in 1:N) {
    Arew[i] = Phi_approx(mu_pr[1] + sigma[1] * Arew_pr[i]);
    Apun[i] = Phi_approx(mu_pr[2] + sigma[2] * Apun_pr[i]);
    R[i]    = Phi_approx(mu_pr[3] + sigma[3] * R_pr[i]) * 30;
    P[i]    = Phi_approx(mu_pr[4] + sigma[4] * P_pr[i]) * 30;
  }
}

model {
  // Hyperparameters
  mu_pr  ~ normal(0, 1);
  sigma ~ normal(0, 0.2);

  // individual parameters
  Arew_pr  ~ normal(0, 1.0);
  Apun_pr  ~ normal(0, 1.0);
  R_pr     ~ normal(0, 1.0);
  P_pr     ~ normal(0, 1.0);

  for (i in 1:N) {
    // Define values
    vector[Narm] Qr;
    vector[Narm] Qp;
    vector[Narm] PEr_fic; // prediction error - for reward fictive updating (for unchosen options)
    vector[Narm] PEp_fic; // prediction error - for punishment fictive updating (for unchosen options)
    vector[Narm] Qsum;    // Qsum = Qrew + Qpun + perseverance

    real Qr_chosen;
    real Qp_chosen;
    real PEr; // prediction error - for reward of the chosen option
    real PEp; // prediction error - for punishment of the chosen option

    // Initialize values
    Qr    = initV;
    Qp    = initV;
    Qsum  = initV;

    for (t in 1:Tsubj[i]) {
      // softmax choice
      choice[i, t] ~ categorical_logit(Qsum);

      // Prediction error signals
      PEr     = R[i] * rew[i, t] - Qr[choice[i, t]];
      PEp     = P[i] * los[i, t] - Qp[choice[i, t]];
      PEr_fic = -Qr;
      PEp_fic = -Qp;

      // store chosen deck Q values (rew and pun)
      Qr_chosen = Qr[choice[i, t]];
      Qp_chosen = Qp[choice[i, t]];

      // First, update Qr & Qp for all decks w/ fictive updating
      Qr += Arew[i] * PEr_fic;
      Qp += Apun[i] * PEp_fic;
      // Replace Q values of chosen deck with correct values using stored values
      Qr[choice[i, t]] = Qr_chosen + Arew[i] * PEr;
      Qp[choice[i, t]] = Qp_chosen + Apun[i] * PEp;

      // Q(sum)
      Qsum = Qr + Qp;
    }
  }
}
generated quantities {
  // For group level parameters
  real<lower=0, upper=1> mu_Arew;
  real<lower=0, upper=1> mu_Apun;
  real<lower=0, upper=30> mu_R;
  real<lower=0, upper=30> mu_P;

  // For log likelihood calculation
  real log_lik[N];

  // For posterior predictive check
  real y_pred[N, T];

  // Matrix to store prediction errors
  matrix[N, T] pred_error;

  // Set all posterior predictions to 0 (avoids NULL values)
  for (i in 1:N) {
    for (t in 1:T) {
      y_pred[i, t] = -1;
    }
  }

  mu_Arew = Phi_approx(mu_pr[1]);
  mu_Apun = Phi_approx(mu_pr[2]);
  mu_R    = Phi_approx(mu_pr[3]) * 30;
  mu_P    = Phi_approx(mu_pr[4]) * 30;

  { // local section, this saves time and space
    for (i in 1:N) {
      // Define values
      vector[Narm] Qr;
      vector[Narm] Qp;
      vector[Narm] PEr_fic; // prediction error - for reward fictive updating (for unchosen options)
      vector[Narm] PEp_fic; // prediction error - for punishment fictive updating (for unchosen options)
      vector[Narm] Qsum;    // Qsum = Qrew + Qpun + perseverance

      real Qr_chosen;
      real Qp_chosen;
      real PEr; // prediction error - for reward of the chosen option
      real PEp; // prediction error - for punishment of the chosen option

      // Initialize values
      Qr   = initV;
      Qp   = initV;
      Qsum = initV;
      log_lik[i] = 0.0;

      for (t in 1:Tsubj[i]) {
        // compute log likelihood of current trial
        log_lik[i] += categorical_logit_lpmf(choice[i, t] | Qsum);

        // generate posterior prediction for current trial
        y_pred[i, t] = categorical_rng(softmax(Qsum));

        // Prediction error signals
        PEr     = R[i] * rew[i, t] - Qr[choice[i, t]];
        PEp     = P[i] * los[i, t] - Qp[choice[i, t]];
        pred_error[i, t] = PEr; // Store prediction error for reward
        PEr_fic = -Qr;
        PEp_fic = -Qp;

        // store chosen deck Q values (rew and pun)
        Qr_chosen = Qr[choice[i, t]];
        Qp_chosen = Qp[choice[i, t]];

        // First, update Qr & Qp for all decks w/ fictive updating
        Qr += Arew[i] * PEr_fic;
        Qp += Apun[i] * PEp_fic;
        // Replace Q values of chosen deck with correct values using stored values
        Qr[choice[i, t]] = Qr_chosen + Arew[i] * PEr;
        Qp[choice[i, t]] = Qp_chosen + Apun[i] * PEp;

        // Q(sum)
        Qsum = Qr + Qp;
      }
    }
  }
}

"""

# Compile the model
sm = pystan.StanModel(model_code=stan_model_code)

fit = sm.sampling(data=stan_data, iter=4000, warmup=2000, chains=4, seed=123, refresh=400)

"""Check fit"""

results = fit.extract(permuted=True)
Arew = results['Arew']
Apun = results['Apun']
R = results['R']
P = results['P']

print(fit)

fit_summary = fit.summary()
print(fit_summary)

rhats = fit_summary['summary'][:, -1]
if all(rhats < 1.05):
    print("All R-hat values are below 1.05, indicating potential convergence.")
else:
    print("Some R-hat values exceed 1.05, indicating potential lack of convergence.")

problematic_parameters = fit_summary['summary_rownames'][rhats > 1.05]
print("Parameters with potential convergence issues:", problematic_parameters)

"""MCMC Trace plots check"""

# Trace plot
import matplotlib.pyplot as plt
import numpy as np

# Assume 'fit' is your fitted model from PyStan
parameter_name = 'mu_Apun'  # Replace with your actual parameter name
num_chains = fit.sim['chains']
num_warmup = fit.sim['warmup']  # Number of warm-up iterations

# Extract the samples for the specific parameter
samples_dict = fit.extract(permuted=True)
samples = samples_dict[parameter_name]

# Determine the total number of iterations (including warm-up)
total_iterations = len(samples)

# Reshape the samples to separate the chains
# Each chain's samples are concatenated; reshape to separate them
samples_reshaped = np.reshape(samples, (total_iterations // num_chains, num_chains))

plt.figure(figsize=(10, 4))

# Differentiate chains and warm-up phase
colors = ['blue', 'green', 'red', 'purple']  # Add more colors if you have more than 4 chains
for i in range(num_chains):
    chain_samples = samples_reshaped[:, i]
    # Plot warm-up samples
    plt.plot(chain_samples[:num_warmup], color=colors[i], linestyle='--', alpha=0.7, label=f'Chain {i+1} Warm-up' if i == 0 else '')
    # Plot post-warm-up samples
    plt.plot(range(num_warmup, total_iterations // num_chains), chain_samples[num_warmup:], color=colors[i], label=f'Chain {i+1}' if i == 0 else '')

plt.title(f'Trace Plot for {parameter_name}')
plt.xlabel('Iteration')
plt.ylabel('Parameter Value')
#plt.legend()
plt.show()

"""Posterior Distribution"""

# Posterior distribution plot
# Assuming 'fit' is your fitted model from PyStan
samples = fit.extract(permuted=True)  # This should be a dictionary

# Now, try to access the desired parameter
try:
    arew_samples = samples['Apun']
    # Plotting
    plt.figure(figsize=(7, 4))
    plt.hist(arew_samples, bins=30, density=True)
    #plt.title('Posterior Distribution for Arew')
    plt.xlabel('Arew (Reward Learning Rate)')
    plt.ylabel('Density')
    plt.show()
except KeyError:
    print("Parameter 'Arew' not found in the samples. Check the parameter name.")

"""Extract prediction errors"""

import numpy as np
import pandas as pd

# Extract the 'pred_error' variable from the fit
pred_error = fit.extract(permuted=True)['pred_error']

# Calculate the mean across the sample dimension (assuming 8000 samples)
# You can also use np.median if that's more appropriate for your analysis
pred_error_mean = np.mean(pred_error, axis=0)

# Assuming 'Tsubj' (number of trials for each subject) is part of your data
# If 'Tsubj' is not in the original data dictionary, you need to define it here
Tsubj = stan_data['Tsubj']

# Initialize a list to store mean prediction errors for each subject
subject_pred_errors = []

# Loop over each subject to extract their specific prediction errors
for i in range(len(Tsubj)):
    num_trials = Tsubj[i]  # Number of trials for subject i
    subject_error = pred_error_mean[i, :num_trials]  # Slice the array for the number of trials
    subject_pred_errors.append(subject_error)

# Now, 'subject_pred_errors' contains the mean prediction errors per subject
# Each element in the list corresponds to a subject

# Convert the list of arrays into a DataFrame
# Each row in the DataFrame corresponds to a subject
df = pd.DataFrame.from_records(subject_pred_errors)

# Optionally, add a column for subject IDs
df.insert(0, 'SubjectID', range(1, 1 + len(df)))

# Save to CSV
df.to_csv('prediction_errors.csv', index=False)

"""Plotting y_pred"""

# Extract y_pred from the Stan model fit, assuming the shape might need reconsideration for arm separation
y_pred = fit.extract('y_pred')['y_pred']  # Shape: (8000, 10, 300)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assume y_pred is already loaded and shaped as (num_simulations, num_subjects, num_trials)
num_simulations, num_subjects, num_trials = y_pred.shape
num_arms = 3
num_trials = 200  # Adjust to use only the first 200 trials

# Initialize a one-hot encoded array for arm choices
y_pred_one_hot = np.zeros((num_simulations, num_subjects, num_trials, num_arms))

# Convert y_pred to one-hot encoded format
for arm in range(1, num_arms + 1):
    y_pred_one_hot[..., arm - 1] = (y_pred[:, :, :num_trials] == arm)

# Calculate the mean probability of choosing each arm
y_pred_probabilities = np.mean(y_pred_one_hot, axis=0)

# Load your actual data
data = pd.read_csv('merged_ANH_stan.csv')
data = data[data['trial'] <= 200]  # Filter to only include the first 200 trials

# Prepare the probabilities data for merging
prob_cols = [f'prob_arm_{i+1}' for i in range(num_arms)]
probabilities_df = pd.DataFrame(y_pred_probabilities.reshape(-1, num_arms), columns=prob_cols)
probabilities_df['trial'] = np.tile(np.arange(1, num_trials + 1), num_subjects)
probabilities_df['subjid'] = np.repeat(np.arange(1, num_subjects + 1), num_trials)

# Merge the probabilities with the actual data
data_merged = pd.merge(data, probabilities_df, on=['subjid', 'trial'], how='left')

# Plotting for each subject
for subjid in data_merged['subjid'].unique():
    sample_data = data_merged[data_merged['subjid'] == subjid]

    plt.figure(figsize=(10, 6))
    for i in range(num_arms):
        sns.lineplot(x='trial', y=f'prob_arm_{i+1}', data=sample_data, label=f'Arm {i+1}')

    # Plot original choices as scatter plot with y-offsets
    scatter_y = np.ones(len(sample_data)) * 1.05  # Slightly above 1 for visibility
    sns.scatterplot(x='trial', y=scatter_y, hue='choice', data=sample_data,
                    palette='deep', legend=None, s=10, marker='o', edgecolor='black')

    plt.title(f'Subject {subjid} - Predicted Probabilities and Actual Choices')
    plt.xlabel('Trial Number')
    plt.ylabel('Probability')
    plt.ylim(0, 1.1)
    plt.legend(title='Predicted Arm')
    plt.show()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming y_pred is already loaded and shaped as (num_simulations, num_subjects, num_trials)
num_simulations, num_subjects, num_trials = y_pred.shape
num_arms = 3
num_trials = 200  # Adjust to use only the first 200 trials

# Initialize a one-hot encoded array for arm choices
y_pred_one_hot = np.zeros((num_simulations, num_subjects, num_trials, num_arms))

# Convert y_pred to one-hot encoded format
for arm in range(1, num_arms + 1):
    y_pred_one_hot[..., arm - 1] = (y_pred[:, :, :num_trials] == arm)

# Calculate the mean probability of choosing each arm
y_pred_probabilities = np.mean(y_pred_one_hot, axis=0)

# Load your actual data
data = pd.read_csv('merged_ANH_stan.csv')
data = data[data['trial'] <= 200]  # Filter to only include the first 200 trials

# Prepare the probabilities data for merging
prob_cols = [f'prob_arm_{i+1}' for i in range(num_arms)]
probabilities_df = pd.DataFrame(y_pred_probabilities.reshape(-1, num_arms), columns=prob_cols)
probabilities_df['trial'] = np.tile(np.arange(1, num_trials + 1), num_subjects)
probabilities_df['subjid'] = np.repeat(np.arange(1, num_subjects + 1), num_trials)

# Merge the probabilities with the actual data
data_merged = pd.merge(data, probabilities_df, on=['subjid', 'trial'], how='left')

# Plotting for each subject
for subjid in data_merged['subjid'].unique():
    sample_data = data_merged[data_merged['subjid'] == subjid]

    plt.figure(figsize=(15, 9))  # Larger figure size
    for i in range(num_arms):
        sns.lineplot(x='trial', y=f'prob_arm_{i+1}', data=sample_data, label=f'Arm {i+1}', linewidth=2.5)  # Thicker lines

    # Plot original choices as scatter plot with y-offsets and jitter
    scatter_y = np.ones(len(sample_data)) * 1.05  # Slightly above 1 for visibility
    jitter = np.random.normal(0, 0.2, size=len(sample_data))
    trial_with_jitter = sample_data['trial'] + jitter
    sns.scatterplot(x=trial_with_jitter, y=scatter_y, hue='choice', data=sample_data,
                    palette='deep', legend=None, s=120, marker='d', edgecolor='black', alpha=0.7)  # Larger markers

    plt.title(f'Subject {subjid} - Predicted Probabilities and Actual Choices', fontsize=16)
    plt.xlabel('Trial Number', fontsize=14)
    plt.ylabel('Probability', fontsize=14)
    plt.xticks(fontsize=12)
    plt.yticks(fontsize=12)
    plt.ylim(0, 1.1)
    plt.legend(title='Predicted Arm', title_fontsize='13', fontsize='12')
    plt.show()